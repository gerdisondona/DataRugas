{"cells":[{"cell_type":"code","source":["# LEITURA DOS ARQUIVOS PARQUET NA PASTA NOVOS\n","\n","# Lê o arquivo Parquet contendo os dados da aba \"Receita\" e cria um DataFrame Spark\n","df_receita = spark.read.parquet(\"Files/Abas/Receita.parquet\")\n","\n","# CRIAR UMA VISÃO TEMPORÁRIA PARA USAR SQL\n","\n","# Cria ou substitui uma *temporary view* chamada \"df_receita\"\n","# Isso permite executar consultas SQL diretamente sobre esse DataFrame\n","df_receita.createOrReplaceTempView(\"df_receita\")\n","\n","# A consulta SQL abaixo transforma os dados da receita\n","df_receita_alucar = spark.sql(\"\"\"\n","    SELECT\n","       Nome_Alucar as NOME,                             -- Renomeia a coluna \"Nome_Alucar\" para \"NOME\"\n","       DATE_FORMAT(Data, 'dd/MM/yyyy') AS DATA,         -- Formata a data para o formato brasileiro (ex: 08/07/2025)\n","       MONTH(Data) AS MES,                              -- Extrai o número do mês da coluna \"Data\"\n","       year(Data) AS ANO,                               -- Extrai o ano da coluna \"Data\"\n","       CAST(Valor_Receita AS FLOAT) AS VALOR_RECEITA    -- Converte a receita para tipo FLOAT\n","    FROM\n","        df_receita                                      -- Fonte: visão temporária criada acima\n","    WHERE MONTH(Data) IS NOT NULL                       -- Filtra apenas linhas com valor de mês válido\n","    ORDER BY MONTH(Data), Data  ASC                     -- Ordena por mês e depois por data\n","\"\"\")\n","\n","\n","# Salva o resultado da consulta como uma tabela permanente chamada \"receita_alucar\"\n","# O modo \"overwrite\" substitui a tabela se ela já existir\n","df_receita_alucar.write.mode(\"overwrite\").saveAsTable(\"receita_alucar\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"971db938-9b8c-4ea3-ac3c-3850dbbc882a","normalized_state":"finished","queued_time":"2025-07-08T18:13:33.1713017Z","session_start_time":null,"execution_start_time":"2025-07-08T18:13:33.1725341Z","execution_finish_time":"2025-07-08T18:13:41.1671719Z","parent_msg_id":"9904d663-ee4a-43be-8794-10f5f10b0a32"},"text/plain":"StatementMeta(, 971db938-9b8c-4ea3-ac3c-3850dbbc882a, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"73ee42fe-152d-4f26-a868-cee15ea572da"},{"cell_type":"code","source":["# Importações necessárias do PySpark\n","from pyspark.sql.functions import col, lag, trim, monotonically_increasing_id, when, lit, collect_list, udf\n","from pyspark.sql.window import Window\n","from pyspark.sql.types import IntegerType, StringType\n","\n","# Lê o arquivo Parquet da aba \"Receita\"\n","df_receita = spark.read.parquet(\"Files/Abas/Receita.parquet\")\n","\n","# Cria uma visão temporária para usar SQL\n","df_receita.createOrReplaceTempView(\"df_receita\")\n","\n","# Consulta os dados relevantes para o ConsigCar (nome do mês, ano e valor)\n","df_ConsigCar = spark.sql(\"\"\"\n","    SELECT Faturamento_ConsigCar, Ano,Valor\n","    FROM df_receita\n","\"\"\")\n","\n","# Cria uma coluna com ID artificial (para manter a ordem original, já que Parquet não garante isso)\n","df_raw_com_id = df_ConsigCar.withColumn(\"row_id\", monotonically_increasing_id())\n","\n","# Define uma janela de ordenação baseada no ID artificial\n","window_spec = Window.orderBy(\"row_id\")\n","\n","# Usa a função `lag` para pegar o valor da linha anterior (supostamente o nome do mês da linha anterior à \"Pagseguro\")\n","df_with_mes = df_raw_com_id.withColumn(\"MES\", lag(\"Faturamento_ConsigCar\").over(window_spec))\n","\n","# Converte os nomes dos meses em números\n","df_with_mes = df_with_mes.withColumn(\n","    \"MES_NUMERO\",\n","    when(col(\"MES\") == \"JANEIRO\", 1)\n","    .when(col(\"MES\") == \"FEVEREIRO\", 2)\n","    .when(col(\"MES\") == \"MARÇO\", 3)\n","    .when(col(\"MES\") == \"ABRIL\", 4)\n","    .when(col(\"MES\") == \"MAIO\", 5)\n","    .when(col(\"MES\") == \"JUNHO\", 6)\n","    .when(col(\"MES\") == \"JULHO\", 7)\n","    .when(col(\"MES\") == \"AGOSTO\", 8)\n","    .when(col(\"MES\") == \"SETEMBRO\", 9)\n","    .when(col(\"MES\") == \"OUTUBRO\", 10)\n","    .when(col(\"MES\") == \"NOVEMBRO\", 11)\n","    .when(col(\"MES\") == \"DEZEMBRO\", 12)\n","    .otherwise(None)\n",")\n","\n","# Filtra apenas as linhas que correspondem ao item \"Pagseguro\" (os valores monetários) e transforma o ano em inteiro para facilitar operações posteriores\n","df_pagseguro = df_with_mes.filter(trim(col(\"Faturamento_ConsigCar\")) == \"Pagseguro\") \\\n","    .withColumn(\"Ano_int\", col(\"Ano\").cast(\"int\"))\n","\n","# Coleta os meses que já têm ano 2025 para evitar repetição incorreta de ano\n","meses_2025 = (\n","    df_pagseguro.filter(col(\"Ano\") == 2025)\n","    .select(\"MES_NUMERO\")\n","    .distinct()\n","    .rdd.flatMap(lambda x: x)\n","    .collect()\n",")\n","\n","# Compartilha a lista de meses de 2025 com os nós do cluster (broadcast variable)\n","meses_2025_broadcast = spark.sparkContext.broadcast(set(meses_2025))\n","\n","# Define uma função UDF para corrigir o ano com base no mês:\n","#    - Se o ano já estiver preenchido, mantém\n","#    - Se o mês já apareceu em 2025, assume que pertence a 2026\n","#    - Caso contrário, assume que é de 2025\n","def corrigir_ano(mes, ano):\n","    if ano is not None:\n","        return int(ano)\n","    if mes in meses_2025_broadcast.value:\n","        return 2026\n","    return 2025\n","\n","\n","# Registra a função UDF para uso no DataFrame\n","corrigir_ano_udf = udf(corrigir_ano, IntegerType())\n","\n","# Aplica a UDF no DataFrame para gerar a nova coluna \"Ano_corrigido\"\n","df_final = df_pagseguro.withColumn(\"Ano_corrigido\", corrigir_ano_udf(col(\"MES_NUMERO\"), col(\"Ano_int\")))\n","\n","# Seleciona e renomeia as colunas finais formatadas\n","df_consigcar = df_final.filter(trim(col(\"Faturamento_ConsigCar\")) == \"Pagseguro\") \\\n","    .selectExpr(\n","        \"'Faturamento_ConsigCar' as NOME\",   # Nome fixo\n","        \"Ano_corrigido as Ano\",              # Ano corrigido\n","        \"MES_NUMERO as MES\",                 # Número do mês\n","        \"CAST(Valor AS FLOAT) AS Valor\"      # Valor convertido para float\n","    )\n","\n","# Salva o resultado final como uma tabela chamada \"receita_consigcar\"\n","df_consigcar.write.mode(\"overwrite\").saveAsTable(\"receita_consigcar\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"971db938-9b8c-4ea3-ac3c-3850dbbc882a","normalized_state":"finished","queued_time":"2025-07-08T18:13:33.2397362Z","session_start_time":null,"execution_start_time":"2025-07-08T18:13:41.1696681Z","execution_finish_time":"2025-07-08T18:13:47.4957142Z","parent_msg_id":"5b854c16-73c3-43e1-a5f3-4993d04f7c85"},"text/plain":"StatementMeta(, 971db938-9b8c-4ea3-ac3c-3850dbbc882a, 18, Finished, Available, Finished)"},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1a8bf2b1-7994-4519-9193-f0f0f6befd19"},{"cell_type":"code","source":["# Importações necessárias do panda\n","import pandas as pd\n","\n","# LEITURA DO ARQUIVO PARQUET DA ABA \"Despesas\"\n","df_despesas = spark.read.parquet(\"Files/Abas/Despesas.parquet\")\n","\n","# CONVERSÃO DO DATAFRAME SPARK PARA PANDAS\n","df = df_despesas.toPandas()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","session_id":"971db938-9b8c-4ea3-ac3c-3850dbbc882a","normalized_state":"finished","queued_time":"2025-07-08T18:13:33.2934162Z","session_start_time":null,"execution_start_time":"2025-07-08T18:13:47.4980786Z","execution_finish_time":"2025-07-08T18:13:48.4019441Z","parent_msg_id":"0977af1d-b8d2-46d4-8b15-73bdcb749587"},"text/plain":"StatementMeta(, 971db938-9b8c-4ea3-ac3c-3850dbbc882a, 19, Finished, Available, Finished)"},"metadata":{}}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9886a0a3-c02c-4d81-ae67-274e31fd3029"},{"cell_type":"code","source":["# Filtra as linhas da coluna '1' que contenham as palavras 'ALUCAR' ou 'CONSIGCAR' (case-insensitive)\n","filtro = df['1'].str.contains('ALUCAR|CONSIGCAR', case=False, na=False)\n","\n","# Aplica o filtro no DataFrame para obter somente as linhas que satisfazem o critério\n","resultado = df[filtro]\n","\n","# Seleciona apenas as colunas '1' e 'linha_ordem' para análise\n","df_filtrado = resultado[['1', 'linha_ordem']]\n","\n","# Filtra ainda mais para obter só as linhas que contém 'CONSIGCAR' na coluna '1'\n","df_filtrado_consigcar = df_filtrado['1'].str.contains('CONSIGCAR', case=False, na=False)\n","reslultato_consigcar = df_filtrado[df_filtrado_consigcar]\n","\n","# Pega somente a coluna 'linha_ordem' das linhas filtradas com 'CONSIGCAR'\n","x = reslultato_consigcar[['linha_ordem']]\n","\n","# Extrai o valor da linha_ordem da primeira ocorrência para usar como ponto de corte\n","valor_linha = int(x['linha_ordem'].values[0])\n","\n","# Divide o DataFrame original em duas partes:\n","# Da linha 0 até valor_linha - 1 (inclusive)\n","df_1 = df.iloc[0:valor_linha]  # ou .iloc[0:25] se quiser da primeira até a linha 24\n","\n","# Da linha valor_linha até o fim\n","df_2 = df.iloc[valor_linha:]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"971db938-9b8c-4ea3-ac3c-3850dbbc882a","normalized_state":"finished","queued_time":"2025-07-08T18:13:33.4503755Z","session_start_time":null,"execution_start_time":"2025-07-08T18:13:48.404473Z","execution_finish_time":"2025-07-08T18:13:48.6987894Z","parent_msg_id":"8f4be94a-d976-4d07-8311-d4c91fc45fc8"},"text/plain":"StatementMeta(, 971db938-9b8c-4ea3-ac3c-3850dbbc882a, 20, Finished, Available, Finished)"},"metadata":{}}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"baa94dfb-901d-49d1-8a35-b9e46f1b638b"},{"cell_type":"code","source":["# Converte o DataFrame Pandas df_1 para um DataFrame Spark\n","df_1_spark  = spark.createDataFrame(df_1)\n","\n","# Cria ou substitui uma visão temporária chamada \"df_despesas_alucar\"\n","df_1_spark.createOrReplaceTempView(\"df_despesas_alucar\")\n","\n","# Executa uma consulta SQL para selecionar e renomear as colunas da view criada\n","df_despesas_alucar = spark.sql(\"\"\"\n","    SELECT \n","            `0` AS NOME,\n","            `1` AS JANEIRO,\n","            `2` AS FEVEIRO,\n","            `3` AS `MARÇO`,\n","            `4` AS ABRIL,\n","            `5` AS MAIO,\n","            `6` AS JUNHO,\n","            `7` AS JULHO,            \n","            `8` AS AGOSTO,\n","            `9` AS SETEMBRO,\n","            `10` AS OUTUBRO,\n","            `11` AS NOVEMBRO,\n","            `12` AS DEZEMBRO\n","    FROM df_despesas_alucar\n","    WHERE  `0` NOT IN ('nan', 'DESPESAS', 'TOTAL')\n","\"\"\")\n","\n","# Salva o DataFrame Spark como tabela permanente chamada \"despesas_alucar\"\n","df_despesas_alucar.write.mode(\"overwrite\").saveAsTable(\"despesas_alucar\")\n","\n","# Repete o processo para o segundo DataFrame df_2 (que contém dados referentes a ConsigCar)\n","df_2 = spark.createDataFrame(df_2)\n","\n","# Cria visão temporária para df_2\n","df_2.createOrReplaceTempView(\"df_despesas_consigcar\")\n","\n","# Consulta SQL para selecionar e renomear colunas de df_2\n","df_despesas_consigcar = spark.sql(\"\"\"\n","    SELECT \n","            `0` AS NOME,\n","            `1` AS JANEIRO,\n","            `2` AS FEVEIRO,\n","            `3` AS `MARÇO`,\n","            `4` AS ABRIL,\n","            `5` AS MAIO,\n","            `6` AS JUNHO,\n","            `7` AS JULHO,            \n","            `8` AS AGOSTO,\n","            `9` AS SETEMBRO,\n","            `10` AS OUTUBRO,\n","            `11` AS NOVEMBRO,\n","            `12` AS DEZEMBRO\n","    FROM df_despesas_consigcar\n","    WHERE  `0` NOT IN ('nan', 'DESPESAS', 'TOTAL')\n","\"\"\")\n","\n","# Salva o DataFrame Spark como tabela permanente chamada \"despesas_consigcar\"\n","df_despesas_consigcar.write.mode(\"overwrite\").saveAsTable(\"despesas_consigcar\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"971db938-9b8c-4ea3-ac3c-3850dbbc882a","normalized_state":"finished","queued_time":"2025-07-08T18:13:33.5344016Z","session_start_time":null,"execution_start_time":"2025-07-08T18:13:48.7008552Z","execution_finish_time":"2025-07-08T18:14:00.8223265Z","parent_msg_id":"d8cffd9b-1e00-4b71-9dd4-6bafd755ad10"},"text/plain":"StatementMeta(, 971db938-9b8c-4ea3-ac3c-3850dbbc882a, 21, Finished, Available, Finished)"},"metadata":{}}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"0d46a88d-dae0-46b4-a88d-2d2abb5f2794"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"8b8ad78f-3700-4dda-bf30-605ce73cb5b6","known_lakehouses":[{"id":"8b8ad78f-3700-4dda-bf30-605ce73cb5b6"},{"id":"5b685ac1-a3d0-4c5f-8a72-76aa5073ddf4"}],"default_lakehouse_name":"Silver","default_lakehouse_workspace_id":"19171b58-1312-460f-b28d-71a85c76db66"}}},"nbformat":4,"nbformat_minor":5}